{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GTN One-Stop Tutorial (Python)\n",
        "\n",
        "This notebook is a comprehensive curriculum-style tutorial for **GTN** using the Python APIs and examples in this repository.\n",
        "\n",
        "It is organized from fundamentals to advanced topics:\n",
        "\n",
        "1. Graph basics (WFSA/WFST)\n",
        "2. Core graph operations\n",
        "3. Scoring and differentiation\n",
        "4. Sequence criteria (ASG, CTC)\n",
        "5. String algorithms (n-grams, edit distance)\n",
        "6. Learned decompositions and hand-designed priors\n",
        "7. Sequence alignment\n",
        "8. Linear-chain CRF and PyTorch integration\n",
        "\n",
        "It cross-references these example scripts in `bindings/python/examples/`:\n",
        "\n",
        "- `simple_graph.py`\n",
        "- `asg.py`\n",
        "- `ctc.py`\n",
        "- `count_ngrams.py`\n",
        "- `edit_distance.py`\n",
        "- `learned_decompositions.py`\n",
        "- `priors.py`\n",
        "- `tutorial.py`\n",
        "- `sequence_alignment.py`\n",
        "- `word_decompositions.py`\n",
        "- `linear_crf.py`\n",
        "- `pytorch_loss.py`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Prerequisites\n",
        "\n",
        "You need:\n",
        "\n",
        "- `gtn` installed from this repo (`python -m pip install ./bindings/python`)\n",
        "- Graphviz (`dot`) installed for drawing\n",
        "\n",
        "If needed in WSL (Ubuntu/Debian):\n",
        "\n",
        "```bash\n",
        "bash ./scripts/install_wsl.sh\n",
        "sudo apt install -y graphviz\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "import gtn\n",
        "from IPython.display import SVG, display, Markdown\n",
        "\n",
        "print(\"GTN imported. version:\", getattr(gtn, \"__version__\", \"unknown\"))\n",
        "print(\"CUDA available:\", gtn.cuda.is_available() if hasattr(gtn, \"cuda\") else False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Notebook paths\n",
        "NB_DIR = Path.cwd()\n",
        "OUT_DIR = NB_DIR / \"_gtn_tutorial_artifacts\"\n",
        "OUT_DIR.mkdir(exist_ok=True)\n",
        "OUT_DIR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def draw_svg(graph, name, isymbols=None, osymbols=None):\n",
        "    \"\"\"Draw graph via GTN -> .dot, then Graphviz -> .svg, and display inline.\"\"\"\n",
        "    dot_path = OUT_DIR / f\"{name}.dot\"\n",
        "    svg_path = OUT_DIR / f\"{name}.svg\"\n",
        "    gtn.draw(graph, str(dot_path), isymbols or {}, osymbols or {})\n",
        "    subprocess.check_call([\"dot\", \"-Tsvg\", str(dot_path), \"-o\", str(svg_path)])\n",
        "    display(SVG(filename=str(svg_path)))\n",
        "    return dot_path, svg_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Theory Primer: Weighted Graphs in GTN\n",
        "\n",
        "A GTN graph is a weighted finite-state automaton/transducer.\n",
        "\n",
        "- **Nodes**: states\n",
        "- **Arcs**: transitions with labels and weights\n",
        "- **Start / accept states** define valid paths\n",
        "\n",
        "In log-space, path score is arc-weight sum:\n",
        "\n",
        "$$s(\\pi)=\\sum_{a\\in\\pi} w_a$$\n",
        "\n",
        "Forward score is log-sum-exp over accepting paths:\n",
        "\n",
        "$$\\log Z = \\log\\sum_{\\pi\\in\\mathcal{A}} e^{s(\\pi)}$$\n",
        "\n",
        "Viterbi score is max over paths:\n",
        "\n",
        "$$\\max_{\\pi\\in\\mathcal{A}} s(\\pi)$$\n",
        "\n",
        "GTN also supports autograd through graph operations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Graph Basics (from `simple_graph.py` and `tutorial.py`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build three acceptors like bindings/python/examples/simple_graph.py\n",
        "symbols = {0: \"a\", 1: \"b\", 2: \"c\"}\n",
        "\n",
        "g1 = gtn.Graph(False)\n",
        "g1.add_node(True)\n",
        "g1.add_node()\n",
        "g1.add_node(False, True)\n",
        "g1.add_arc(0, 1, 0)\n",
        "g1.add_arc(1, 2, 1)\n",
        "g1.add_arc(2, 2, 0)\n",
        "\n",
        "g2 = gtn.Graph(False)\n",
        "g2.add_node(True)\n",
        "g2.add_node()\n",
        "g2.add_node(False, True)\n",
        "g2.add_arc(0, 1, 1)\n",
        "g2.add_arc(1, 2, 0)\n",
        "\n",
        "g3 = gtn.Graph(False)\n",
        "g3.add_node(True)\n",
        "g3.add_node()\n",
        "g3.add_node(False, True)\n",
        "g3.add_arc(0, 1, 0)\n",
        "g3.add_arc(1, 2, 2)\n",
        "\n",
        "print(\"g1 nodes/arcs:\", g1.num_nodes(), g1.num_arcs())\n",
        "draw_svg(g1, \"simple_g1\", symbols, symbols)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Acceptor vs Transducer\n",
        "\n",
        "- **Acceptor**: one label stream (input labels; output defaults to input)\n",
        "- **Transducer**: separate input/output labels per arc\n",
        "\n",
        "Epsilon label is `gtn.epsilon` and represents empty symbol transitions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "isymbols = {0: \"a\", 1: \"b\", 2: \"c\"}\n",
        "osymbols = {0: \"x\", 1: \"y\", 2: \"z\"}\n",
        "\n",
        "fst = gtn.Graph()\n",
        "fst.add_node(True)\n",
        "fst.add_node()\n",
        "fst.add_node(False, True)\n",
        "fst.add_arc(0, 1, 0)       # output defaults to input\n",
        "fst.add_arc(0, 1, 1, 1)\n",
        "fst.add_arc(1, 2, 1, 2)    # explicit transduction b->z\n",
        "draw_svg(fst, \"simple_fst\", isymbols, osymbols)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Core Operations (`tutorial.py`)\n",
        "\n",
        "### 3.1 Union, Concat, Closure\n",
        "\n",
        "- `union([g1, g2, ...])`: accepts any string accepted by any input graph\n",
        "- `concat(g1, g2)`: accepts strings `xy` where `x` in `g1`, `y` in `g2`\n",
        "- `closure(g)`: Kleene closure, zero or more repetitions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "u = gtn.union([g1, g2, g3])\n",
        "c = gtn.concat(g2, g3)\n",
        "k = gtn.closure(g2)\n",
        "\n",
        "draw_svg(u, \"union_graph\", symbols)\n",
        "draw_svg(c, \"concat_graph\", symbols)\n",
        "draw_svg(k, \"closure_graph\", symbols)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Compose, Intersect, Project, Remove\n",
        "\n",
        "- `compose(g1, g2)`: WFST composition (output labels of `g1` match input labels of `g2`)\n",
        "- `intersect(g1, g2)`: acceptor intersection\n",
        "- `project_input` / `project_output`: turn transducer to acceptor by selecting one side\n",
        "- `remove(..., gtn.epsilon)`: epsilon-removal/simplification in many setups\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Two simple acceptors for intersection\n",
        "a = gtn.Graph()\n",
        "a.add_node(True)\n",
        "a.add_node(False, True)\n",
        "a.add_arc(0, 0, 0)\n",
        "a.add_arc(0, 1, 1)\n",
        "a.add_arc(1, 1, 2)\n",
        "\n",
        "b = gtn.Graph()\n",
        "for i in range(4):\n",
        "    b.add_node(i == 0, i == 3)\n",
        "for src in [0, 1, 2]:\n",
        "    for lab in [0, 1, 2]:\n",
        "        b.add_arc(src, src + 1, lab)\n",
        "\n",
        "inter = gtn.intersect(a, b)\n",
        "draw_svg(inter, \"intersect_graph\", symbols)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Forward/Viterbi and Autograd (`tutorial.py`)\n",
        "\n",
        "GTN supports both differentiable marginal scoring (`forward_score`) and max-path decoding (`viterbi_score`, `viterbi_path`).\n",
        "\n",
        "For differentiable objectives:\n",
        "\n",
        "1. Build objective graph operations\n",
        "2. Get scalar loss graph\n",
        "3. Call `gtn.backward(loss)`\n",
        "4. Read gradients from `.grad()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g = gtn.Graph()\n",
        "g.add_node(True)\n",
        "g.add_node(True)\n",
        "g.add_node()\n",
        "g.add_node(False, True)\n",
        "g.add_arc(0, 1, 0, 0, 1.1)\n",
        "g.add_arc(0, 2, 1, 1, 3.2)\n",
        "g.add_arc(1, 2, 2, 2, 1.4)\n",
        "g.add_arc(2, 3, 0, 0, 2.1)\n",
        "\n",
        "fs = gtn.forward_score(g)\n",
        "vs = gtn.viterbi_score(g)\n",
        "vp = gtn.viterbi_path(g)\n",
        "\n",
        "print(\"forward score:\", fs.item())\n",
        "print(\"viterbi score:\", vs.item())\n",
        "draw_svg(vp, \"viterbi_path\", symbols)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Autograd toy example\n",
        "g1 = gtn.Graph()\n",
        "g1.add_node(True)\n",
        "g1.add_node()\n",
        "g1.add_node(False, True)\n",
        "g1.add_arc(0, 1, 0)\n",
        "g1.add_arc(0, 1, 1)\n",
        "g1.add_arc(1, 2, 0)\n",
        "g1.add_arc(1, 2, 1)\n",
        "\n",
        "g2 = gtn.Graph(False)  # no-grad graph\n",
        "g2.add_node(True)\n",
        "g2.add_node(False, True)\n",
        "g2.add_arc(0, 0, 0)\n",
        "g2.add_arc(0, 1, 1)\n",
        "\n",
        "a = gtn.forward_score(gtn.compose(g1, g2))\n",
        "b = gtn.forward_score(g1)\n",
        "loss = gtn.subtract(b, a)\n",
        "gtn.backward(loss)\n",
        "print(\"g1 grad weights:\", g1.grad().weights_to_list())\n",
        "g1.zero_grad()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. ASG Criterion (`asg.py`)\n",
        "\n",
        "ASG can be written as:\n",
        "\n",
        "$$\\mathcal{L}_{ASG}=\\log Z_{full} - \\log Z_{target}$$\n",
        "\n",
        "where:\n",
        "\n",
        "- `Z_target`: constrained force-alignment graph score\n",
        "- `Z_full`: unconstrained/full-connect score\n",
        "\n",
        "Both are graph forward scores composed with emissions and transitions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "N = 27\n",
        "T = 5\n",
        "target = [2, 0, 19]\n",
        "\n",
        "emissions = gtn.linear_graph(T, N)\n",
        "\n",
        "transitions = gtn.Graph()\n",
        "transitions.add_node(True)\n",
        "for i in range(1, N + 1):\n",
        "    transitions.add_node(False, True)\n",
        "    transitions.add_arc(0, i, i - 1)\n",
        "for i in range(N):\n",
        "    for j in range(N):\n",
        "        transitions.add_arc(i + 1, j + 1, j)\n",
        "\n",
        "fal = gtn.Graph()\n",
        "fal.add_node(True)\n",
        "for idx, lab in enumerate(target, start=1):\n",
        "    fal.add_node(False, idx == len(target))\n",
        "    fal.add_arc(idx, idx, lab)\n",
        "    fal.add_arc(idx - 1, idx, lab)\n",
        "\n",
        "fal_align = gtn.compose(emissions, gtn.compose(fal, transitions))\n",
        "full_align = gtn.compose(emissions, transitions)\n",
        "loss_asg = gtn.subtract(gtn.forward_score(full_align), gtn.forward_score(fal_align))\n",
        "\n",
        "print(\"ASG loss:\", loss_asg.item())\n",
        "gtn.backward(loss_asg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. CTC Criterion (`ctc.py`)\n",
        "\n",
        "CTC adds a blank symbol and specific transition constraints.\n",
        "\n",
        "Standard graph form:\n",
        "\n",
        "$$\\mathcal{L}_{CTC} = -\\log Z_{ctc}$$\n",
        "\n",
        "when emissions are already normalized per frame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_ctc_target_graph(target, blank=0):\n",
        "    L = len(target)\n",
        "    U = 2 * L + 1\n",
        "    ctc = gtn.Graph()\n",
        "    for p in range(U):\n",
        "        idx = (p - 1) // 2\n",
        "        ctc.add_node(p == 0, p in (U - 1, U - 2))\n",
        "        label = target[idx] if p % 2 else blank\n",
        "        ctc.add_arc(p, p, label)\n",
        "        if p > 0:\n",
        "            ctc.add_arc(p - 1, p, label)\n",
        "        if p % 2 and p > 1 and label != target[idx - 1]:\n",
        "            ctc.add_arc(p - 2, p, label)\n",
        "    return ctc\n",
        "\n",
        "ctc_target = create_ctc_target_graph([3, 1, 20], blank=0)\n",
        "emissions = gtn.linear_graph(5, 28)\n",
        "ctc_align = gtn.compose(ctc_target, emissions)\n",
        "ctc_loss = gtn.negate(gtn.forward_score(ctc_align))\n",
        "print(\"CTC loss:\", ctc_loss.item())\n",
        "gtn.backward(ctc_loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Counting n-grams (`count_ngrams.py`)\n",
        "\n",
        "A neat perspective: many symbolic counting problems can be phrased as graph composition + forward scoring.\n",
        "\n",
        "Count extraction is done via `exp(log_count)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_chain(tokens):\n",
        "    g = gtn.Graph(False)\n",
        "    g.add_node(True)\n",
        "    for i, tok in enumerate(tokens):\n",
        "        g.add_node(False, i == len(tokens) - 1)\n",
        "        g.add_arc(i, i + 1, tok)\n",
        "    return g\n",
        "\n",
        "def make_ngram_counter(n, num_tokens):\n",
        "    g = gtn.linear_graph(n, num_tokens)\n",
        "    for i in range(num_tokens):\n",
        "        g.add_arc(0, 0, i, gtn.epsilon)\n",
        "        g.add_arc(n, n, i, gtn.epsilon)\n",
        "    return g\n",
        "\n",
        "input_g = make_chain([0, 1, 0, 1])\n",
        "ngram_g = make_chain([0, 1])\n",
        "counter = make_ngram_counter(2, 2)\n",
        "score = gtn.forward_score(gtn.compose(input_g, gtn.compose(counter, ngram_g)))\n",
        "count = int(round(math.exp(score.item())))\n",
        "print(\"count([0,1] in [0,1,0,1]) =\", count)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Edit Distance (`edit_distance.py` and `sequence_alignment.py`)\n",
        "\n",
        "Levenshtein distance via weighted edit transducer:\n",
        "\n",
        "- substitution cost: 0 for match, -1 for mismatch\n",
        "- insertion/deletion cost: -1\n",
        "\n",
        "Then distance is `-viterbi_score(compose(x, compose(edits, y)))`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_edits_graph(num_tokens):\n",
        "    edits = gtn.Graph(False)\n",
        "    edits.add_node(True, True)\n",
        "    for i in range(num_tokens):\n",
        "        for j in range(num_tokens):\n",
        "            edits.add_arc(0, 0, i, j, -int(i != j))\n",
        "        edits.add_arc(0, 0, i, gtn.epsilon, -1)\n",
        "        edits.add_arc(0, 0, gtn.epsilon, i, -1)\n",
        "    return edits\n",
        "\n",
        "x = make_chain([0, 1, 0, 1])\n",
        "y = make_chain([0, 0, 0, 1, 1])\n",
        "edits = make_edits_graph(5)\n",
        "d = int(-gtn.viterbi_score(gtn.compose(x, gtn.compose(edits, y))).item())\n",
        "print(\"Levenshtein distance:\", d)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Learned Decompositions (`word_decompositions.py`, `learned_decompositions.py`, `priors.py`)\n",
        "\n",
        "These examples show a major GTN advantage: you can inject structure/priors by graph construction.\n",
        "\n",
        "### Key idea\n",
        "\n",
        "Build token/decomposition graphs and compose with emissions/targets to define training criteria with custom alignments.\n",
        "\n",
        "This unifies:\n",
        "\n",
        "- ASG-like constraints\n",
        "- CTC-like blank behavior\n",
        "- alternative subword decompositions\n",
        "- hand-designed bias constraints\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mini decomposition example from word_decompositions.py\n",
        "letters = {\"a\": 0, \"b\": 1, \"c\": 2}\n",
        "idx_to_let = {v: k for k, v in letters.items()}\n",
        "\n",
        "word_pieces = [\"a\", \"b\", \"c\", \"ab\", \"bc\", \"ac\", \"abc\"]\n",
        "idx_to_wp = dict(enumerate(word_pieces))\n",
        "\n",
        "def lexicon_graph(word_pieces, letters_to_idx):\n",
        "    lex = []\n",
        "    for i, wp in enumerate(word_pieces):\n",
        "        g = gtn.Graph()\n",
        "        g.add_node(True)\n",
        "        for e, l in enumerate(wp):\n",
        "            g.add_node(False, e == len(wp) - 1)\n",
        "            out = i if e == len(wp) - 1 else gtn.epsilon\n",
        "            g.add_arc(e, e + 1, letters_to_idx[l], out)\n",
        "        lex.append(g)\n",
        "    return gtn.closure(gtn.union(lex))\n",
        "\n",
        "def token_graph(tokens):\n",
        "    gs = []\n",
        "    for i in range(len(tokens)):\n",
        "        g = gtn.Graph()\n",
        "        g.add_node(True)\n",
        "        g.add_node(False, True)\n",
        "        g.add_arc(0, 1, i, i)\n",
        "        g.add_arc(1, 1, i, gtn.epsilon)\n",
        "        gs.append(g)\n",
        "    return gtn.closure(gtn.union(gs))\n",
        "\n",
        "lex = lexicon_graph(word_pieces, letters)\n",
        "tokens = token_graph(word_pieces)\n",
        "\n",
        "abc = gtn.Graph(False)\n",
        "abc.add_node(True)\n",
        "abc.add_node()\n",
        "abc.add_node()\n",
        "abc.add_node(False, True)\n",
        "abc.add_arc(0, 1, letters[\"a\"])\n",
        "abc.add_arc(1, 2, letters[\"b\"])\n",
        "abc.add_arc(2, 3, letters[\"c\"])\n",
        "\n",
        "abc_decomps = gtn.remove(gtn.project_output(gtn.compose(abc, lex)))\n",
        "abc_align = gtn.project_input(gtn.remove(gtn.compose(tokens, abc_decomps)))\n",
        "draw_svg(abc_align, \"abc_alignments\", idx_to_wp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Biological Sequence Alignment (`sequence_alignment.py`)\n",
        "\n",
        "The sequence alignment example builds a scoring transducer using BLOSUM and gap penalties, then decodes best alignment with Viterbi.\n",
        "\n",
        "Needleman-Wunsch (global) vs Smith-Waterman (local) is represented by start/accept state choices.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RESIDUE_MAP = {r: i for i, r in enumerate(\"ARNDCQEGHILKMFPSTWYV\")}\n",
        "\n",
        "def resolve_blosum_path():\n",
        "    candidates = [\n",
        "        Path(\"../../bindings/python/examples/blosum.json\"),\n",
        "        Path(\"bindings/python/examples/blosum.json\"),\n",
        "        Path(\"../bindings/python/examples/blosum.json\"),\n",
        "    ]\n",
        "    for p in candidates:\n",
        "        if p.exists():\n",
        "            return p\n",
        "    raise FileNotFoundError(\"Could not locate blosum.json\")\n",
        "\n",
        "BLOSUM = json.loads(resolve_blosum_path().read_text())\n",
        "\n",
        "def make_score_graph(gap_open=-8, gap_add=-8):\n",
        "    g = gtn.Graph()\n",
        "    g.add_node(True, True)\n",
        "    affine = (gap_open != gap_add)\n",
        "    if affine:\n",
        "        g.add_node(False, True)\n",
        "        g.add_node(False, True)\n",
        "    for k, v in BLOSUM.items():\n",
        "        r1, r2 = k\n",
        "        g.add_arc(0, 0, RESIDUE_MAP[r1], RESIDUE_MAP[r2], v)\n",
        "        if affine:\n",
        "            g.add_arc(1, 0, RESIDUE_MAP[r1], RESIDUE_MAP[r2], v)\n",
        "            g.add_arc(2, 0, RESIDUE_MAP[r1], RESIDUE_MAP[r2], v)\n",
        "    for r in RESIDUE_MAP.values():\n",
        "        if affine:\n",
        "            g.add_arc(0, 1, r, gtn.epsilon, gap_open)\n",
        "            g.add_arc(1, 1, r, gtn.epsilon, gap_add)\n",
        "            g.add_arc(0, 2, gtn.epsilon, r, gap_open)\n",
        "            g.add_arc(2, 2, gtn.epsilon, r, gap_add)\n",
        "        else:\n",
        "            g.add_arc(0, 0, r, gtn.epsilon, gap_open)\n",
        "            g.add_arc(0, 0, gtn.epsilon, r, gap_open)\n",
        "    return g\n",
        "\n",
        "def make_seq_graph(seq, alg=\"nw\"):\n",
        "    g = gtn.Graph()\n",
        "    start = (alg == \"sw\")\n",
        "    accept = (alg == \"sw\")\n",
        "    g.add_node(start=True, accept=accept)\n",
        "    for e, s in enumerate(seq):\n",
        "        g.add_node(start=start, accept=accept or (e == len(seq) - 1))\n",
        "        g.add_arc(e, e + 1, RESIDUE_MAP[s])\n",
        "    return g\n",
        "\n",
        "seq_a = \"HEAGAWGHEE\"\n",
        "seq_b = \"PAWHEAE\"\n",
        "score_g = make_score_graph()\n",
        "ali = gtn.compose(gtn.compose(make_seq_graph(seq_a, \"nw\"), score_g), make_seq_graph(seq_b, \"nw\"))\n",
        "print(\"NW score:\", gtn.viterbi_score(ali).item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Linear-Chain CRF (`linear_crf.py`)\n",
        "\n",
        "Linear CRF with GTN is usually represented as:\n",
        "\n",
        "$$\\mathcal{L}=\\log Z(x)-s(x,y)$$\n",
        "\n",
        "where:\n",
        "\n",
        "- `s(x,y)` is score of the target label path graph\n",
        "- `Z(x)` is partition function from all-path graph\n",
        "\n",
        "The script `linear_crf.py` contains a full trainable example.\n",
        "\n",
        "Suggested workflow in notebook:\n",
        "\n",
        "1. Open `bindings/python/examples/linear_crf.py`\n",
        "2. Keep data generation and training loop as-is\n",
        "3. Use notebook cells to inspect intermediate graphs (`target_graph`, `norm_graph`)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. PyTorch Integration (`pytorch_loss.py`)\n",
        "\n",
        "GTN can be used inside custom autograd functions to compute sequence losses while training neural nets in PyTorch.\n",
        "\n",
        "The `pytorch_loss.py` example demonstrates:\n",
        "\n",
        "- converting NN emissions into GTN graph weights\n",
        "- computing sequence objective with GTN\n",
        "- backpropagating to PyTorch tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(Markdown(\"Run this from repo root to execute the full PyTorch example: `python bindings/python/examples/pytorch_loss.py`\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Suggested Learning Path (Curriculum)\n",
        "\n",
        "### Stage A: Foundations\n",
        "\n",
        "1. `simple_graph.py`\n",
        "2. `tutorial.py` sections on core ops and forward/viterbi\n",
        "\n",
        "### Stage B: Sequence Criteria\n",
        "\n",
        "3. `asg.py`\n",
        "4. `ctc.py`\n",
        "5. `priors.py`\n",
        "\n",
        "### Stage C: Symbolic Algorithms\n",
        "\n",
        "6. `count_ngrams.py`\n",
        "7. `edit_distance.py`\n",
        "8. `sequence_alignment.py`\n",
        "\n",
        "### Stage D: Rich Structure and Training\n",
        "\n",
        "9. `word_decompositions.py`\n",
        "10. `learned_decompositions.py`\n",
        "11. `linear_crf.py`\n",
        "12. `pytorch_loss.py`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Practical Tips\n",
        "\n",
        "- Prefer log-space reasoning for numerical stability.\n",
        "- Keep graphs acyclic for `forward_score` unless you know behavior for cycles.\n",
        "- Use `remove(..., gtn.epsilon)` strategically for simpler/faster compositions.\n",
        "- Inspect with Graphviz early (`draw_svg`) when debugging.\n",
        "- Reset gradients with `zero_grad()` before reusing graphs in iterative loops.\n",
        "- Keep criterion definitions declarative: compose constraints from reusable graph blocks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Where to Go Next\n",
        "\n",
        "- Reproduce each script in `bindings/python/examples` directly.\n",
        "- Turn one criterion (ASG/CTC/CRF) into your own task-specific graph.\n",
        "- Profile composition order; associativity allows multiple equivalent factorizations with very different speed.\n",
        "- Explore CUDA backend when available.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
